{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup nltk corpora path and Google Word2Vec location\n",
    "nltk_path = os.sep.join([os.environ['HOME'], 'nltk_data'])\n",
    "google_vec_file = '/Users/warren/Data_Science/Metis/github/project-kojak/GoogleNews-vectors-negative300.bin.gz'\n",
    "\n",
    "nltk.data.path.insert(0, nltk_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Kramer DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load prompts\n",
    "with open('kramer_responses.pkl', 'rb') as file:\n",
    "    df_kramer_01 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize, encode, pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ep_num</th>\n",
       "      <th>scene_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>char_prompt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>char_response</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>GEORGE</td>\n",
       "      <td>did you need something .</td>\n",
       "      <td>KRAMER</td>\n",
       "      <td>do you handle any of that commercial .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>JERRY</td>\n",
       "      <td>you cant look in there , were playing !</td>\n",
       "      <td>KRAMER</td>\n",
       "      <td>hi .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>MORTY</td>\n",
       "      <td>kramer !</td>\n",
       "      <td>KRAMER</td>\n",
       "      <td>hey morty !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>JERRY</td>\n",
       "      <td>dad , shes cheating !</td>\n",
       "      <td>KRAMER</td>\n",
       "      <td>quo ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>HELEN</td>\n",
       "      <td>32 .</td>\n",
       "      <td>KRAMER</td>\n",
       "      <td>no , you dont have to challenge that .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ep_num  scene_num  line_num char_prompt  \\\n",
       "137       1          6        30      GEORGE   \n",
       "437       2          9         6       JERRY   \n",
       "440       2          9         9       MORTY   \n",
       "446       2          9        15       JERRY   \n",
       "470       2          9        39       HELEN   \n",
       "\n",
       "                                      prompt char_response  \\\n",
       "137                 did you need something .        KRAMER   \n",
       "437  you cant look in there , were playing !        KRAMER   \n",
       "440                                 kramer !        KRAMER   \n",
       "446                    dad , shes cheating !        KRAMER   \n",
       "470                                     32 .        KRAMER   \n",
       "\n",
       "                                   response  \n",
       "137  do you handle any of that commercial .  \n",
       "437                                    hi .  \n",
       "440                             hey morty !  \n",
       "446                                   quo ?  \n",
       "470  no , you dont have to challenge that .  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The loaded data\n",
    "df_kramer_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6239, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kramer_01.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6208, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = df_kramer_01.response.apply(lambda x: len(nltk.word_tokenize(x)) <= 27)\n",
    "df_kramer_01[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_kramer_02 = df_kramer_01[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 48.3 ms, total: 1.85 s\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Tokenize the data\n",
    "prompts_tokenized = [nltk.word_tokenize(line) for line in df_kramer_02.prompt]\n",
    "responses_tokenized = [nltk.word_tokenize(line) for line in df_kramer_02.response]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "print(max([len(line) for line in prompts_tokenized]))\n",
    "print(max([len(line) for line in responses_tokenized]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 32s, sys: 29 s, total: 4min 1s\n",
      "Wall time: 6min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(google_vec_file, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 191 ms, sys: 174 ms, total: 365 ms\n",
      "Wall time: 704 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Encode the data using word2vec\n",
    "# sentend is of length 300 because word2vec encodes words as length 300 vectors\n",
    "\n",
    "sentend = np.ones((300,), dtype = np.float32) \n",
    "\n",
    "prompts_encoded = [[word2vec[word] for word in line if word in word2vec.vocab] for line in prompts_tokenized]\n",
    "responses_encoded = [[word2vec[word] for word in line if word in word2vec.vocab] for line in responses_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20019531,  0.15429688,  0.10302734,  0.00866699,  0.00118256], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_encoded[0][0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = prompts_encoded[0]\n",
    "test[14:] = []\n",
    "test.append(sentend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(max([len(p) for p in prompts_encoded]))\n",
    "print(max([len(p) for p in responses_encoded]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 76.4 ms, sys: 4.86 ms, total: 81.3 ms\n",
      "Wall time: 87 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Padding / adding sentence end tokens\n",
    "# Make more efficient/pythonic?\n",
    "\n",
    "for tok_sent in prompts_encoded:\n",
    "    tok_sent[23:]=[]\n",
    "    tok_sent.append(sentend)\n",
    "    \n",
    "\n",
    "for tok_sent in prompts_encoded:\n",
    "    if len(tok_sent)<24:\n",
    "        for i in range(24-len(tok_sent)):\n",
    "            tok_sent.append(sentend)  \n",
    "\n",
    "\n",
    "for tok_sent in responses_encoded:\n",
    "    tok_sent[23:]=[]\n",
    "    tok_sent.append(sentend)\n",
    "\n",
    "\n",
    "for tok_sent in responses_encoded:\n",
    "    if len(tok_sent)<24:\n",
    "        for i in range(24-len(tok_sent)):\n",
    "            tok_sent.append(sentend)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('kramer_source_list_w2v.pickle','wb') as file:\n",
    "    pickle.dump(prompts_encoded, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('kramer_response_list_w2v.pickle','wb') as file:\n",
    "    pickle.dump(responses_encoded, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
